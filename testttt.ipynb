{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import fabs\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def robust_min(img, p=5):\n",
    "    return np.percentile(img.ravel(), p)\n",
    "\n",
    "\n",
    "def robust_max(img, p=95):\n",
    "    return np.percentile(img.ravel(), p)\n",
    "\n",
    "\n",
    "def normalize(img, m=10, M=90):\n",
    "    return np.clip((img - robust_min(img, m)) / (robust_max(img, M) - robust_min(img, m)), 0.0, 1.0)\n",
    "\n",
    "\n",
    "def first_element_greater_than(values, req_value):\n",
    "    \"\"\"Returns the pair (i, values[i]) such that i is the minimum value that satisfies values[i] >= req_value.\n",
    "    Returns (-1, None) if there is no such i.\n",
    "    Note: this function assumes that values is a sorted array!\"\"\"\n",
    "    i = np.searchsorted(values, req_value)\n",
    "    val = values[i] if i < len(values) else None\n",
    "    return (i, val)\n",
    "\n",
    "\n",
    "def last_element_less_than(values, req_value):\n",
    "    \"\"\"Returns the pair (i, values[i]) such that i is the maximum value that satisfies values[i] <= req_value.\n",
    "    Returns (-1, None) if there is no such i.\n",
    "    Note: this function assumes that values is a sorted array!\"\"\"\n",
    "    i = np.searchsorted(values, req_value, side='right') - 1\n",
    "    val = values[i] if i >= 0 else None\n",
    "    return (i, val)\n",
    "\n",
    "\n",
    "def closest_element_to(values, req_value):\n",
    "    \"\"\"Returns the tuple (i, values[i], diff) such that i is the closest value to req_value,\n",
    "    and diff = |values(i) - req_value|\n",
    "    Note: this function assumes that values is a sorted array!\"\"\"\n",
    "    assert(len(values) > 0)\n",
    "\n",
    "    i = np.searchsorted(values, req_value, side='left')\n",
    "    if i > 0 and (i == len(values) or fabs(req_value - values[i - 1]) < fabs(req_value - values[i])):\n",
    "        idx = i - 1\n",
    "        val = values[i - 1]\n",
    "    else:\n",
    "        idx = i\n",
    "        val = values[i]\n",
    "\n",
    "    diff = fabs(val - req_value)\n",
    "    return (idx, val, diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wasse\\AppData\\Local\\Temp\\ipykernel_21684\\14396457.py:20: DeprecationWarning: `alltrue` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `all` instead.\n",
      "  self.read_timestamps()\n"
     ]
    }
   ],
   "source": [
    "data = EventDataset(\"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\\", \"test_sequence_00_town10\\\\events\\\\data\\\\\", start_time=0, stop_time=0, transform=None, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wasse\\AppData\\Local\\Temp\\ipykernel_21684\\14396457.py:20: DeprecationWarning: `alltrue` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `all` instead.\n",
      "  self.read_timestamps()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VoxelGridDataset at 0x18987161930>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VoxelGridDataset(\"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\\", \"test_sequence_00_town10\\\\events\\\\data\\\\\", start_time=0, stop_time=0, transform=None, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelGridDataset(EventDataset):\n",
    "    \"\"\"Load an event folder containing event tensors encoded with the VoxelGrid format.\"\"\"\n",
    "\n",
    "    def parse_event_folder(self):\n",
    "        \"\"\"Check that the passed directory has the following form:\n",
    "\n",
    "        ├── event_folder\n",
    "        |   ├── timestamps.txt\n",
    "        |   ├── event_tensor_0000000000.npy\n",
    "        |   ├── ...\n",
    "        |   ├── event_tensor_<N>.npy\n",
    "        \"\"\"\n",
    "        self.num_bins = None\n",
    "\n",
    "    def num_channels(self):\n",
    "        return self.num_bins\n",
    "\n",
    "    def __getitem__(self, i, transform_seed=None):\n",
    "        assert(i >= 0)\n",
    "        assert(i < self.length)\n",
    "\n",
    "        if transform_seed is None:\n",
    "            transform_seed = random.randint(0, 2**32)\n",
    "\n",
    "        # event_tensor will be a [num_bins x H x W] floating point array\n",
    "        event_tensor = np.load(join(self.event_folder, 'event_tensor_{:010d}.npy'.format(self.first_valid_idx + i)))\n",
    "        if self.normalize:\n",
    "            # normalize the event tensor (voxel grid) in such a way that the mean and stddev of the nonzero values\n",
    "            # in the tensor are equal to (0.0, 1.0)\n",
    "            mask = np.nonzero(event_tensor)\n",
    "            if mask[0].size > 0:\n",
    "                mean, stddev = event_tensor[mask].mean(), event_tensor[mask].std()\n",
    "                if stddev > 0:\n",
    "                    event_tensor[mask] = (event_tensor[mask] - mean) / stddev\n",
    "\n",
    "        self.num_bins = event_tensor.shape[0]\n",
    "\n",
    "        events = torch.from_numpy(event_tensor)  # [C x H x W]\n",
    "        if self.transform:\n",
    "            random.seed(transform_seed)\n",
    "            events = self.transform(events)\n",
    "\n",
    "        return {'events': events}  # [num_bins x H x W] tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original events: 0\n",
      "Total filtered events: 0\n"
     ]
    }
   ],
   "source": [
    "import dv_processing as dv\n",
    "import numpy as np\n",
    "import torch\n",
    "from os.path import join\n",
    "from datetime import timedelta\n",
    "import cv2 as cv\n",
    "\n",
    "# Event filtering classes\n",
    "class AdaptiveThresholdFilter:\n",
    "    def __init__(self, resolution, adaptation_rate=0.01, decay_rate=0.1):\n",
    "        self.resolution = resolution\n",
    "        self.adaptation_rate = adaptation_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.threshold_map = np.zeros(resolution, dtype=np.float32)\n",
    "\n",
    "    def apply(self, events):\n",
    "        filtered_events = []\n",
    "        for event in events:\n",
    "            x, y = int(event[0]), int(event[1])\n",
    "            if 0 <= x < self.resolution[0] and 0 <= y < self.resolution[1]:\n",
    "                self.threshold_map[x, y] += self.adaptation_rate\n",
    "                if abs(event[3]) > self.threshold_map[x, y]:\n",
    "                    filtered_events.append(event)\n",
    "                self.threshold_map[x, y] *= (1 - self.decay_rate)\n",
    "        return np.array(filtered_events)\n",
    "\n",
    "def density_filter(events, resolution, min_density=10, max_density=100):\n",
    "    width, height = resolution\n",
    "    grid = np.zeros((width, height), dtype=np.int32)\n",
    "    for event in events:\n",
    "        x, y = int(event[0]), int(event[1])\n",
    "        if 0 <= x < width and 0 <= y < height:\n",
    "            grid[x, y] += 1\n",
    "    return np.array([event for event in events if min_density <= grid[int(event[0]), int(event[1])] <= max_density])\n",
    "\n",
    "# Dataset class\n",
    "class NPYEventDataset:\n",
    "    def __init__(self, base_folder, event_folder, resolution=(640, 480)):\n",
    "        self.base_folder = base_folder\n",
    "        self.event_folder = join(self.base_folder, event_folder)\n",
    "        self.resolution = resolution\n",
    "        self.files = self.load_event_files()\n",
    "\n",
    "    def load_event_files(self):\n",
    "        import glob\n",
    "        return sorted(glob.glob(join(self.event_folder, 'event_tensor_*.npy')))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.files[idx])  # Load raw numpy event data\n",
    "        return data.reshape(-1, 4)  # Expecting [x, y, timestamp, polarity]\n",
    "\n",
    "def process_events(dataset, filter_type=\"adaptive\"):\n",
    "    total_original_events = 0\n",
    "    total_filtered_events = 0\n",
    "\n",
    "    adaptive_filter = AdaptiveThresholdFilter(resolution=(640, 480))\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        events = dataset[i]\n",
    "        total_original_events += len(events)\n",
    "\n",
    "        if filter_type == \"density\":\n",
    "            filtered_events = density_filter(events, resolution=(640, 480))\n",
    "        elif filter_type == \"adaptive\":\n",
    "            filtered_events = adaptive_filter.apply(events)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown filter type\")\n",
    "\n",
    "        total_filtered_events += len(filtered_events)\n",
    "\n",
    "        # Save filtered events\n",
    "        np.savetxt(f'filtered_events_{i}.txt', filtered_events, fmt='%d')\n",
    "\n",
    "        print(f\"File {i}: Original events = {len(events)}, Filtered events = {len(filtered_events)}\")\n",
    "\n",
    "    print(f\"Total original events: {total_original_events}\")\n",
    "    print(f\"Total filtered events: {total_filtered_events}\")\n",
    "\n",
    "# Usage\n",
    "\n",
    "base_folder = \"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\\"\n",
    "event_folder = \"test_sequence_00_town10\\\\events\\\\data\\\\\"\n",
    "dataset = NPYEventDataset(base_folder, event_folder)\n",
    "process_events(dataset, filter_type=\"adaptive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\test_sequence_00_town10\\\\events\\\\data\\\\events_0000000003.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original events: 4422840\n",
      "Total filtered events: 3667420\n"
     ]
    }
   ],
   "source": [
    "import dv_processing as dv\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "class AdaptiveThresholdFilter:\n",
    "    def __init__(self, resolution, adaptation_rate=0.1, decay_rate=0.05):\n",
    "        self.resolution = resolution\n",
    "        self.adaptation_rate = adaptation_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.threshold_map = np.zeros(resolution, dtype=np.float32)\n",
    "\n",
    "    def apply(self, events):\n",
    "        filtered_events = []\n",
    "        for event in events:\n",
    "            x, y = int(event.x()), int(event.y())  # x, y coordinates\n",
    "            if 0 <= x < self.resolution[0] and 0 <= y < self.resolution[1]:\n",
    "                self.threshold_map[x, y] += self.adaptation_rate\n",
    "                #print(f\"Threshold for ({x},{y}): {self.threshold_map[x, y]}\")  # Debugging\n",
    "                if abs(event.polarity()) > self.threshold_map[x, y]:  # Polarity thresholding\n",
    "                    filtered_events.append(event)\n",
    "                self.threshold_map[x, y] *= (1 - self.decay_rate)\n",
    "        return filtered_events\n",
    "\n",
    "\n",
    "def density_filter(events, resolution, min_density=10, max_density=100):\n",
    "    width, height = resolution\n",
    "    grid = np.zeros((width, height), dtype=np.int32)\n",
    "    for event in events:\n",
    "        x, y = int(event.x()), int(event.y())  # x, y coordinates\n",
    "        if 0 <= x < width and 0 <= y < height:\n",
    "            grid[x, y] += 1\n",
    "    #print(f\"Grid density: {grid}\")  # Debugging grid density\n",
    "    return [event for event in events if min_density <= grid[int(event.x()), int(event.y())] <= max_density]\n",
    "\n",
    "\n",
    "def save_events(events, output_file):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for event in events:\n",
    "            f.write(f\"{event.timestamp()},{event.x()},{event.y()},{event.polarity()}\\n\")\n",
    "\n",
    "def load_event_data(npy_folder):\n",
    "    event_files = sorted([f for f in os.listdir(npy_folder) if f.endswith('.npy')])\n",
    "    all_events = dv.EventStore()\n",
    "    for file in event_files:\n",
    "        file_path = os.path.join(npy_folder, file)\n",
    "        events = np.load(file_path)  # Load events (timestamp, x, y, polarity)\n",
    "        \n",
    "        for event in events:\n",
    "            timestamp, x, y, polarity = event\n",
    "            # Create dv.Event and add to EventStore\n",
    "            new_event = dv.Event(int(timestamp), int(x), int(y), bool(polarity))\n",
    "            all_events.push_back(new_event)\n",
    "    \n",
    "    return all_events\n",
    "\n",
    "# Load event data\n",
    "npy_folder = \"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\test_sequence_00_town10\\\\events\\\\data\\\\\"\n",
    "all_events = load_event_data(npy_folder)\n",
    "\n",
    "# Initialize filter\n",
    "adaptive_filter = AdaptiveThresholdFilter(resolution=(640, 480))\n",
    "filter_type = \"density\" \n",
    "\n",
    "# Apply filtering\n",
    "if filter_type == \"density\":\n",
    "    filtered_events = density_filter(all_events, resolution=(640, 480))\n",
    "elif filter_type == \"adaptive\":\n",
    "    filtered_events = adaptive_filter.apply(all_events)\n",
    "\n",
    "# Save filtered events\n",
    "save_events(filtered_events, \"filtered_events.txt\")\n",
    "    \n",
    "print(f\"Total original events: {len(all_events)}\")\n",
    "print(f\"Total filtered events: {len(filtered_events)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original events: 4422840\n",
      "Total filtered events: 4422840\n"
     ]
    }
   ],
   "source": [
    "import dv_processing as dv\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "class AdaptiveThresholdFilter:\n",
    "    def __init__(self, resolution, adaptation_rate=0.01, decay_rate=0.1):\n",
    "        self.resolution = resolution\n",
    "        self.adaptation_rate = adaptation_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.threshold_map = np.zeros(resolution, dtype=np.float32)\n",
    "\n",
    "    def apply(self, events):\n",
    "        filtered_events = []\n",
    "        for event in events:\n",
    "            x, y = int(event[1]), int(event[2])  # x, y coordinates\n",
    "            if 0 <= x < self.resolution[0] and 0 <= y < self.resolution[1]:\n",
    "                self.threshold_map[x, y] += self.adaptation_rate\n",
    "                if abs(event[3]) > self.threshold_map[x, y]:  # Polarity thresholding\n",
    "                    filtered_events.append(event)\n",
    "                self.threshold_map[x, y] *= (1 - self.decay_rate)\n",
    "        return filtered_events\n",
    "\n",
    "def density_filter(events, resolution, min_density=10, max_density=100):\n",
    "    width, height = resolution\n",
    "    grid = np.zeros((width, height), dtype=np.int32)\n",
    "    for event in events:\n",
    "        x, y = int(event[1]), int(event[2])  # x, y coordinates\n",
    "        if 0 <= x < width and 0 <= y < height:\n",
    "            grid[x, y] += 1\n",
    "    return [event for event in events if min_density <= grid[int(event[1]), int(event[2])] <= max_density]\n",
    "\n",
    "def save_events(events, output_file):\n",
    "    np.savetxt(output_file, events, fmt=\"%.6f,%d,%d,%d\", delimiter=\",\")\n",
    "\n",
    "def load_event_data(npy_folder):\n",
    "    event_files = sorted([f for f in os.listdir(npy_folder) if f.endswith('.npy')])\n",
    "    all_events = []\n",
    "    for file in event_files:\n",
    "        file_path = os.path.join(npy_folder, file)\n",
    "        events = np.load(file_path)  # Load events (timestamp, x, y, polarity)\n",
    "        all_events.extend(events)\n",
    "    return np.array(all_events)\n",
    "\n",
    "# Load event data\n",
    "npy_folder = \"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\test_sequence_00_town10\\\\events\\\\data\\\\\"\n",
    "all_events = load_event_data(npy_folder)\n",
    "\n",
    "# Initialize filter\n",
    "adaptive_filter = AdaptiveThresholdFilter(resolution=(640, 480))\n",
    "filter_type = \"adaptive\"  # Change to \"density\" for density filtering\n",
    "\n",
    "# Apply filtering\n",
    "if filter_type == \"density\":\n",
    "    filtered_events = density_filter(all_events, resolution=(640, 480))\n",
    "elif filter_type == \"adaptive\":\n",
    "    filtered_events = adaptive_filter.apply(all_events)\n",
    "\n",
    "# Save filtered events\n",
    "save_events(filtered_events, \"filtered_events.txt\")\n",
    "\n",
    "print(f\"Total original events: {len(all_events)}\")\n",
    "print(f\"Total filtered events: {len(filtered_events)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dv_processing as dv\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "class AdaptiveThresholdFilter:\n",
    "    def __init__(self, resolution, adaptation_rate=0.01, decay_rate=0.1):\n",
    "        self.resolution = resolution\n",
    "        self.adaptation_rate = adaptation_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.threshold_map = np.zeros(resolution, dtype=np.float32)\n",
    "\n",
    "    def apply(self, events):\n",
    "        filtered_events = []\n",
    "        for event in events:\n",
    "            x, y = int(event.x()), int(event.y())\n",
    "            if 0 <= x < self.resolution[0] and 0 <= y < self.resolution[1]:\n",
    "                self.threshold_map[x, y] += self.adaptation_rate\n",
    "                if abs(event.polarity()) > self.threshold_map[x, y]:\n",
    "                    filtered_events.append(event)\n",
    "                self.threshold_map[x, y] *= (1 - self.decay_rate)\n",
    "        return filtered_events\n",
    "\n",
    "def density_filter(events, resolution, min_density=10, max_density=100):\n",
    "    width, height = resolution\n",
    "    grid = np.zeros((width, height), dtype=np.int32)\n",
    "    for event in events:\n",
    "        x, y = int(event.x()), int(event.y())\n",
    "        if 0 <= x < width and 0 <= y < height:\n",
    "            grid[x, y] += 1\n",
    "    return [\n",
    "        event for event in events if min_density <= grid[int(event.x()), int(event.y())] <= max_density\n",
    "    ]\n",
    "\n",
    "def save_events(events, output_file):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for event in events:\n",
    "            f.write(f\"{event.x()},{event.y()},{event.timestamp()},{event.polarity()}\\n\")\n",
    "\n",
    "def load_npy_as_eventstore(file_path):\n",
    "    data = np.load(file_path)\n",
    "    timestamps, x_coords, y_coords, polarities = data[:, 0], data[:, 1], data[:, 2], data[:, 3]\n",
    "\n",
    "    event_store = dv.EventStore()\n",
    "    for t, x, y, p in zip(timestamps, x_coords, y_coords, polarities):\n",
    "        event_store.push_back(int(t), int(x), int(y), bool(p))\n",
    "    \n",
    "    return event_store\n",
    "\n",
    "def callback(left_events: dv.EventStore, right_events: dv.EventStore):\n",
    "    global total_original_events, total_filtered_events\n",
    "\n",
    "    # Count original events\n",
    "    original_event_count = len(left_events) + len(right_events)\n",
    "    total_original_events += original_event_count\n",
    "\n",
    "    # Apply filtering\n",
    "    if filter_Events == \"density\":\n",
    "        filtered_left = density_filter(left_events, resolution=(640, 480))\n",
    "        filtered_right = density_filter(right_events, resolution=(640, 480))\n",
    "    elif filter_Events == \"adaptive\":\n",
    "        filtered_left = adaptive_filter.apply(left_events)\n",
    "        filtered_right = adaptive_filter.apply(right_events)\n",
    "\n",
    "    # Count filtered events\n",
    "    filtered_event_count = len(filtered_left) + len(filtered_right)\n",
    "    total_filtered_events += filtered_event_count\n",
    "\n",
    "    # Save filtered events\n",
    "    save_events(filtered_left, \"filtered_left_events.txt\")\n",
    "    save_events(filtered_right, \"filtered_right_events.txt\")\n",
    "\n",
    "    print(f\"Original events: {original_event_count}, Filtered events: {filtered_event_count}\")\n",
    "\n",
    "# Paths to npy files\n",
    "left_npy_file = \"/path/to/left_events.npy\"\n",
    "right_npy_file = \"/path/to/right_events.npy\"\n",
    "\n",
    "# Initialize filter\n",
    "adaptive_filter = AdaptiveThresholdFilter(resolution=(640, 480))\n",
    "filter_Events = \"adaptive\"\n",
    "\n",
    "# Load events from npy files\n",
    "left_events = load_npy_as_eventstore(left_npy_file)\n",
    "right_events = load_npy_as_eventstore(right_npy_file)\n",
    "\n",
    "slicer = dv.StereoEventStreamSlicer()\n",
    "slicer.doEveryTimeInterval(timedelta(milliseconds=33), callback)\n",
    "\n",
    "# Initialize counters\n",
    "total_original_events = 0\n",
    "total_filtered_events = 0\n",
    "\n",
    "# Process loaded event data\n",
    "slicer.accept(left_events, right_events)\n",
    "cv.waitKey(1)\n",
    "\n",
    "# Print final event counts\n",
    "print(f\"Total original events: {total_original_events}\")\n",
    "print(f\"Total filtered events ({filter_Events}): {total_filtered_events}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add(): incompatible function arguments. The following argument types are supported:\n    1. (self: dv_processing.EventStore, other: dv_processing.EventStore) -> None\n\nInvoked with: EventStore containing 0 events within 0µs duration; time range within [0; 0], <dv_processing.EventPacket object at 0x00000189855566F0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Load event data from folder\u001b[39;00m\n\u001b[0;32m     58\u001b[0m npy_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwasse\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrpg_e2depth\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtest_sequence_00_town10\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 59\u001b[0m event_store \u001b[38;5;241m=\u001b[39m \u001b[43mload_event_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpy_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Convert EventStore to a list of dv.Event objects for processing\u001b[39;00m\n\u001b[0;32m     62\u001b[0m all_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(event_store)\n",
      "Cell \u001b[1;32mIn[30], line 51\u001b[0m, in \u001b[0;36mload_event_data\u001b[1;34m(npy_folder)\u001b[0m\n\u001b[0;32m     48\u001b[0m     packet \u001b[38;5;241m=\u001b[39m dv\u001b[38;5;241m.\u001b[39mEventPacket(event_vector)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Add the packet to the event store\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[43mevent_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m event_store\n",
      "\u001b[1;31mTypeError\u001b[0m: add(): incompatible function arguments. The following argument types are supported:\n    1. (self: dv_processing.EventStore, other: dv_processing.EventStore) -> None\n\nInvoked with: EventStore containing 0 events within 0µs duration; time range within [0; 0], <dv_processing.EventPacket object at 0x00000189855566F0>"
     ]
    }
   ],
   "source": [
    "import dv_processing as dv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class AdaptiveThresholdFilter:\n",
    "    def __init__(self, resolution, adaptation_rate=0.01, decay_rate=0.1):\n",
    "        self.resolution = resolution\n",
    "        self.adaptation_rate = adaptation_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.threshold_map = np.zeros(resolution, dtype=np.float32)\n",
    "\n",
    "    def apply(self, events):\n",
    "        filtered_events = []\n",
    "        for event in events:\n",
    "            x, y = event.x, event.y  # x, y coordinates\n",
    "            if 0 <= x < self.resolution[0] and 0 <= y < self.resolution[1]:\n",
    "                self.threshold_map[x, y] += self.adaptation_rate\n",
    "                if abs(event.polarity) > self.threshold_map[x, y]:  # Polarity thresholding\n",
    "                    filtered_events.append(event)\n",
    "                self.threshold_map[x, y] *= (1 - self.decay_rate)\n",
    "        return filtered_events\n",
    "\n",
    "def density_filter(events, resolution, min_density=10, max_density=100):\n",
    "    width, height = resolution\n",
    "    grid = np.zeros((width, height), dtype=np.int32)\n",
    "    for event in events:\n",
    "        x, y = event.x, event.y  # x, y coordinates\n",
    "        if 0 <= x < width and 0 <= y < height:\n",
    "            grid[x, y] += 1\n",
    "    return [event for event in events if min_density <= grid[event.x, event.y] <= max_density]\n",
    "\n",
    "def load_event_data(npy_folder):\n",
    "    event_store = dv.EventStore()\n",
    "    event_files = sorted([f for f in os.listdir(npy_folder) if f.endswith('.npy')])\n",
    "\n",
    "    for file in event_files:\n",
    "        file_path = os.path.join(npy_folder, file)\n",
    "        events_np = np.load(file_path)  # Load events in [timestamp, x, y, polarity] format\n",
    "\n",
    "        # Create an event vector\n",
    "        event_vector = dv.EventPacket.EventVector()\n",
    "\n",
    "        for event in events_np:\n",
    "            timestamp, x, y, polarity = map(int, event)\n",
    "            event_vector.append(dv.Event(timestamp, x, y, polarity))\n",
    "\n",
    "        # Create an event packet with the event vector\n",
    "        packet = dv.EventPacket(event_vector)\n",
    "        \n",
    "        # Add the packet to the event store\n",
    "        event_store.add(packet)\n",
    "\n",
    "    return event_store\n",
    "\n",
    "\n",
    "\n",
    "# Load event data from folder\n",
    "npy_folder = \"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\test_sequence_00_town10\\\\events\\\\data\\\\\"\n",
    "event_store = load_event_data(npy_folder)\n",
    "\n",
    "# Convert EventStore to a list of dv.Event objects for processing\n",
    "all_events = list(event_store)\n",
    "\n",
    "# Apply filtering\n",
    "adaptive_filter = AdaptiveThresholdFilter(resolution=(640, 480))\n",
    "filter_type = \"adaptive\"  # Change to \"density\" for density filtering\n",
    "\n",
    "if filter_type == \"density\":\n",
    "    filtered_events = density_filter(all_events, resolution=(640, 480))\n",
    "elif filter_type == \"adaptive\":\n",
    "    filtered_events = adaptive_filter.apply(all_events)\n",
    "\n",
    "# Save filtered events\n",
    "filtered_event_store = dv.EventStore()\n",
    "for event in filtered_events:\n",
    "    filtered_event_store.add(event)\n",
    "\n",
    "filtered_event_store.save_to_file(\"filtered_events.aedat4\")\n",
    "\n",
    "print(f\"Total original events: {len(all_events)}\")\n",
    "print(f\"Total filtered events: {len(filtered_events)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDocstring:\u001b[0m      A structure defining a brightness change event captured by an event camera\n",
      "\u001b[1;31mInit docstring:\u001b[0m __init__(self: dv_processing.Event, timestamp: int, x: int, y: int, polarity: bool) -> None\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\wasse\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages\\dv_processing.cp310-win_amd64.pyd\n",
      "\u001b[1;31mType:\u001b[0m           pybind11_type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?dv.Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__(): incompatible constructor arguments. The following argument types are supported:\n    1. dv_processing.Event(timestamp: int, x: int, y: int, polarity: bool)\n\nInvoked with: kwargs: x=4471596111, y=107, timestamp=0, polarity=-1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     21\u001b[0m event_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwasse\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrpg_e2depth\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtest_sequence_00_town10\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m event_store \u001b[38;5;241m=\u001b[39m \u001b[43mload_event_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m boundary_timestamps, timesteps \u001b[38;5;241m=\u001b[39m load_timestamps(event_folder)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Now event_store can be passed to the filtering functions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m, in \u001b[0;36mload_event_data\u001b[1;34m(event_folder)\u001b[0m\n\u001b[0;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(event_folder, npy_file))  \u001b[38;5;66;03m# Expecting shape (x, 4)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y, timestamp, polarity \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m---> 11\u001b[0m         event \u001b[38;5;241m=\u001b[39m \u001b[43mdv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEvent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpolarity\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m         events\u001b[38;5;241m.\u001b[39mappend(event)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dv\u001b[38;5;241m.\u001b[39mEventStore(events)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__(): incompatible constructor arguments. The following argument types are supported:\n    1. dv_processing.Event(timestamp: int, x: int, y: int, polarity: bool)\n\nInvoked with: kwargs: x=4471596111, y=107, timestamp=0, polarity=-1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dv_processing as dv\n",
    "import os\n",
    "\n",
    "def load_event_data(event_folder):\n",
    "    npy_files = sorted([f for f in os.listdir(event_folder) if f.endswith('.npy')])\n",
    "    events = []\n",
    "    for npy_file in npy_files:\n",
    "        data = np.load(os.path.join(event_folder, npy_file))  # Expecting shape (x, 4)\n",
    "        for x, y, timestamp, polarity in data:\n",
    "            event = dv.Event(x=int(x), y=int(y), timestamp=int(timestamp), polarity=int(polarity))\n",
    "            events.append(event)\n",
    "    return dv.EventStore(events)\n",
    "\n",
    "def load_timestamps(event_folder):\n",
    "    boundary_timestamps = np.loadtxt(os.path.join(event_folder, 'boundary_timestamps.txt'))\n",
    "    timesteps = np.loadtxt(os.path.join(event_folder, 'timesteps.txt'))\n",
    "    return boundary_timestamps, timesteps\n",
    "\n",
    "# Example usage\n",
    "event_folder = \"C:\\\\Users\\\\wasse\\\\rpg_e2depth\\\\data\\\\test_sequence_00_town10\\\\events\\\\data\\\\\"\n",
    "event_store = load_event_data(event_folder)\n",
    "boundary_timestamps, timesteps = load_timestamps(event_folder)\n",
    "\n",
    "# Now event_store can be passed to the filtering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "class EventDataset(Dataset):\n",
    "    \"\"\"Loads event tensors from a folder, with different event representations.\"\"\"\n",
    "    def __init__(self, base_folder, event_folder, start_time=0, stop_time=0, transform=None, normalize=True):\n",
    "        self.base_folder = base_folder\n",
    "        self.event_folder = join(self.base_folder, event_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.start_time = start_time\n",
    "        self.stop_time = stop_time\n",
    "\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.read_timestamps()\n",
    "\n",
    "        #self.parse_event_folder()\n",
    "\n",
    "    def read_timestamps(self):\n",
    "        # Load the timestamps file\n",
    "        raw_stamps = np.loadtxt(join(self.event_folder, 'timestamps.txt'))\n",
    "\n",
    "        if raw_stamps.size == 0:\n",
    "            raise IOError('Dataset is empty')\n",
    "\n",
    "        if len(raw_stamps.shape) == 1:\n",
    "            # if timestamps.txt has only one entry, the shape will be (2,) instead of (1, 2). fix that.\n",
    "            raw_stamps = raw_stamps.reshape((1, 2))\n",
    "\n",
    "        self.stamps = raw_stamps[:, 1]\n",
    "        if self.stamps is None:\n",
    "            raise IOError('Unable to read timestamp file: '.format(join(self.event_folder,\n",
    "                                                                        'timestamps.txt')))\n",
    "\n",
    "        # Check that the timestamps are unique and sorted\n",
    "        assert(np.alltrue(np.diff(self.stamps) > 0)), \"timestamps are not unique and monotonically increasing\"\n",
    "\n",
    "        self.initial_stamp = self.stamps[0]\n",
    "        self.stamps = self.stamps - self.initial_stamp  # offset the timestamps so they start at 0\n",
    "\n",
    "        # Find the index of the first event tensor whose timestamp >= start_time\n",
    "        # If there is none, throw an error\n",
    "        if self.start_time <= 0.0:\n",
    "            self.first_valid_idx, self.first_stamp = 0, self.stamps[0]\n",
    "        else:\n",
    "            self.first_valid_idx, self.first_stamp = first_element_greater_than(self.stamps, self.start_time)\n",
    "        assert(self.first_stamp is not None)\n",
    "        # print('First valid index / stamp = {}, {}'.format(self.first_valid_idx, self.first_stamp))\n",
    "\n",
    "        # Find the index of the last event tensor whose timestamp <= end_time\n",
    "        # If there is None, throw an error\n",
    "        if self.stop_time <= 0.0:\n",
    "            self.last_valid_idx, self.last_stamp = len(self.stamps) - 1, self.stamps[-1]\n",
    "        else:\n",
    "            self.last_valid_idx, self.last_stamp = last_element_less_than(self.stamps, self.stop_time)\n",
    "        assert(self.last_stamp is not None)\n",
    "        # print('Last valid index / stamp = {}, {}'.format(self.last_valid_idx, self.last_stamp))\n",
    "\n",
    "        assert(self.first_stamp <= self.last_stamp)\n",
    "\n",
    "        self.length = self.last_valid_idx - self.first_valid_idx + 1\n",
    "        assert(self.length > 0)\n",
    "\n",
    "    def parse_event_folder(self):\n",
    "        \"\"\"Parses the event folder to check its validity and read the parameters of the event representation.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def get_last_stamp(self):\n",
    "        \"\"\"Returns the last event timestamp, in seconds.\"\"\"\n",
    "        return self.stamps[self.last_valid_idx]\n",
    "\n",
    "    def num_channels(self):\n",
    "        \"\"\"Returns the number of channels of the event tensor.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_index_at(self, i):\n",
    "        \"\"\"Returns the index of the ith event tensor\"\"\"\n",
    "        return self.first_valid_idx + i\n",
    "\n",
    "    def get_stamp_at(self, i):\n",
    "        \"\"\"Returns the timestamp of the ith event tensor\"\"\"\n",
    "        return self.stamps[self.get_index_at(i)]\n",
    "\n",
    "    def __getitem(self, i):\n",
    "        \"\"\"Returns a C x H x W event tensor for the ith element in the dataset.\"\"\"\n",
    "        raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
